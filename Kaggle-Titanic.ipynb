{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "## Initialize SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "## Load data\n",
    "rawTrainDF = spark.read.format(\"csv\").option(\"header\",True).load(\"kaggletitanic/train.csv\")\n",
    "\n",
    "## Get average of Age for imputation\n",
    "meanAge = rawTrainDF.agg(fn.avg(rawTrainDF[\"Age\"])).collect()[0].__getitem__(\"avg(Age)\")\n",
    "\n",
    "## Impute null Age\n",
    "rawTrainDF = rawTrainDF.na.fill({\"Age\": round(meanAge,1)})\n",
    "\n",
    "rawTrainDF = rawTrainDF.select(fn.col(\"PassengerId\"),fn.col(\"Survived\"),fn.col(\"Sex\"),fn.col(\"Embarked\"),fn.col(\"Pclass\").cast(\"float\"),fn.col(\"Age\").cast(\"float\"),fn.col(\"SibSp\").cast(\"float\"),fn.col(\"Fare\").cast(\"float\"))\n",
    "\n",
    "(trainDF, testDF) = rawTrainDF.randomSplit([0.7,0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "## List categorical features\n",
    "categoricalFeatures = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "## Index categ features\n",
    "indexer = [StringIndexer(inputCol=col, outputCol=col+\"_indexed\",handleInvalid=\"keep\") for col in categoricalFeatures]\n",
    "\n",
    "labelIndexer = [StringIndexer(inputCol=\"Survived\", outputCol=\"Survived_indexed\")]\n",
    "\n",
    "## One Hot Encode indexed features\n",
    "encoder = [OneHotEncoder(inputCol=col+\"_indexed\", outputCol=col+\"_encoded\") for col in categoricalFeatures]\n",
    "\n",
    "## List required features to feed the model\n",
    "requiredFeatures = [\"Pclass\",\"Sex_encoded\",\"Age\",\"SibSp\",\"Fare\",\"Embarked_encoded\"]\n",
    "\n",
    "## Create the vector strucutred data (label, features)\n",
    "assembler = VectorAssembler(inputCols=requiredFeatures, outputCol=\"features\")\n",
    "\n",
    "## Train a RandomForest model\n",
    "rf = RandomForestClassifier(labelCol=\"Survived_indexed\", featuresCol=\"features\")\n",
    "\n",
    "## Create a pipeline to chain indexers and RF\n",
    "pipeline = Pipeline(stages=labelIndexer + indexer + encoder + [assembler, rf])\n",
    "\n",
    "## Train\n",
    "model = pipeline.fit(trainDF)\n",
    "\n",
    "## Predict\n",
    "predictions = model.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.83274\n",
      "f1 = 0.827945\n",
      "weightedPrecision = 0.830243\n",
      "weightedRecall = 0.83274\n"
     ]
    }
   ],
   "source": [
    "## Model evaluation\n",
    "\n",
    "predictions = predictions.select(fn.col(\"Survived\").cast(\"Float\"),fn.col(\"prediction\"))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    " \n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the unlabeled dataset\n",
    "\n",
    "rawTestDF = spark.read.format(\"csv\").option(\"header\",True).load(\"kaggletitanic/test.csv\")\n",
    "\n",
    "rawTestDF = rawTestDF.select(fn.col(\"PassengerId\"),fn.col(\"Sex\"),fn.col(\"Embarked\"),fn.col(\"Pclass\").cast(\"float\"),fn.col(\"Age\").cast(\"float\"),fn.col(\"SibSp\").cast(\"float\"),fn.col(\"Fare\").cast(\"float\"))\n",
    "\n",
    "## Get average of Age for imputation\n",
    "meanAge = rawTestDF.agg(fn.avg(rawTestDF[\"Age\"])).collect()[0].__getitem__(\"avg(Age)\")\n",
    "\n",
    "## Get average of Fare for imputation\n",
    "meanFare = rawTestDF.agg(fn.avg(rawTestDF[\"Fare\"])).collect()[0].__getitem__(\"avg(Fare)\")\n",
    "\n",
    "## Impute null Age\n",
    "rawTestDF = rawTestDF.na.fill({\"Age\": round(meanAge,1)})\n",
    "\n",
    "## Impute null Fare\n",
    "rawTestDF = rawTestDF.na.fill({\"Fare\": round(meanFare,1)})\n",
    "\n",
    "testPred = model.transform(rawTestDF)\n",
    "\n",
    "## Export to CSV\n",
    "testPred.select(\"PassengerId\",fn.col(\"prediction\").alias(\"Survived\")).toPandas().to_csv(path_or_buf=\"gender_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
